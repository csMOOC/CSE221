\chapter{Network}
In this chapter, the two machines are in the same LAN, with network speed about 1000Mb/s.

\section{Round trip time}
In this part, we try to measure the round trip time.

\paragraph{Methodology}
Our method is very simple, it's just like an echo server. Client send one byte to server, when server received the message then send back the message, then client receive it;
Before client send message, we record current cycle time; After client receive message, we record it again. We iterate this procedure for 1000 times and get the average result.


\paragraph{Predictions}
Our predictions exclude the factor of building connection. So for loopback and remote interface, the biggest difference is send and receive data.
For Ping program, we know that it use ICMP packet so it will get more accurate results.
Because Ping exclude the extra time a packet reside in another machine, it will use time timestamp in ICMP packet to calculate time.

Following is the Ping result.
\begin{center}
\begin{tabular}{l*{6}{c}r}
Operation       &  RTT \\
\hline
loopback & 0.070ms & 161000 cycles\\
remote & 0.196ms &  450800 cycles\\
\end{tabular}
\end{center}

Based on Ping results, we made our predictions.

For loopback interface. We measure the hardware overhead is 0.01ms, software overhead is 0.05ms.

For remote interface. We measure the hardware overhead is 0.05ms, software overhead is 0.2ms..

\paragraph{Results}
We present our measured results.

\begin{center}
\begin{tabular}{| p{2cm} | p{3cm} | p{3cm} | p{2.5cm} | p{2.5cm} | p{2cm}}
Operation   & Base Hardware Performance  & Estimated Software Overhead  & Predicted Time  & Measured Time  & Std \\
\hline
Loopback  & 0.01 ms& 0.05 ms& 0.06 ms & 0.03ms & 0.00725ms \\
Remote  & 0.05 ms& 0.2 ms & 0.25 ms & 0.27ms & 0.05ms \\ 
\end{tabular}
\end{center}

\paragraph{Discussion}
The overhead of network communication is large.
Because TCP/IP protocal is implemented in kernel, so even the loopback results are \\

What can you deduce about baseline network performance and the overhead of OS software?  \\
In this experiment we only transfer 1 byte data. In the next experiment, we will go deep into the network performance and the overhead of OS software. Because bandwidth benchmark will reveal more about this. \\

How close to ideal hardware performance do you achieve? \\
It is far short of the ideal hardware performance because of the TCP/IP overhead.\\


What are reasons why the TCP performance does not match ideal hardware performance?  \\
First of all, normal TCP/IP protocols are implemented in kernel, so it is time-consuming to do context switch;
Secondly, We know there are many network stacks, from link layer to TCP/IP stacks;
Moreover, it is expensive to establish TCP connection, which will spend much time on handshake(like ACKs) to make sure the connection is reliable.

\section{Peak bandwidth}
In this part, we try to explore peak bandwidth.

\paragraph{Methodology}
The code is very similar to the previous experiment.

In this experiment, when we establish the connection, the server will send some data to the client and the client will receive this chunk of data. The size of data is a parameter. We have tried use different chunk sizes,  like 1MB date. The result is pretty similar. We add MSG\_WAITALL flag to recv() function. Because recv will immediately return if it detect there are some data in the buffer. So we add this flag to let recv() return if and only if it has received all the data.

We repeat this procedure 100 times and choose the maximum result as our peak bandwidth.

\paragraph{Predictions}
It is 

Because the network bandwidth is 1000Mb/s, which is about 125 MB/s. We predict the remote interface is approximately 125MB/s.

\paragraph{Results}
We present our measured results.

\begin{center}
\begin{tabular}{l*{6}{c}r}
Operation       &  Predicted Speed& Measured Speed\\
\hline
Loopback Peak Bandwidth & 1600 MB/s & 1540 MB/s \\
Remote Peak Bandwidth & 125 MB/s  & 133 MB/s\\
\end{tabular}
\end{center}


\paragraph{Discussion}
Our predictions are very close to the measured results. For loopback interface, the speed is close to the memory bandwidth; For remote interface, the speed is close to the network bandwidth, we think it is because these two machines are in the same LAN.

We also think the bandwidth can be influenced by many factors. For example, if the two machine are far from each other, then the route path is undecidable and the bandwidth will be influenced. \\

How close to ideal hardware performance do you achieve? \\
It is close to the hardware performance due to the perfect experiment environment.

\section{Connection overhead}
In this part, we try to explore connection overhead.

\paragraph{Methodology}
We measure connection setup cycle at client side and connection tear-down cycle at server side.

\paragraph{Predictions}
First, we think it is more expensive to setup the connection than tear down. Because we use handshake protocal to setup the connection.

Based on previous experience on RTT experiment, we made following predictions.

\paragraph{Results}
We present our measured results.

\begin{center}
\begin{tabular}{| p{3cm} | p{3cm} | p{3cm} | p{3cm} | p{3cm} |}
Operation  & Base Hardware Performance  & Estimated Software Overhead  & Predicted Time  & Measured Time   \\
\hline
Loopback Connection Setup & 35000 cycles& 5000 cycles& 40000 cycles& 306665 cycles \\
Loopback Connection Tear-down & 20000 cycles& 3000 cycles& 23000 cycles& 54334 cycles \\
Remote Connection Setup & 300000  cycles& 30000 cycles& 330000 cycles& 622923 cycles\\
Remote Connection Tear-down & 150000  cycles& 15000 cycles& 165000 cycles& 141333 cycles\\
\end{tabular}
\end{center}


\paragraph{Discussion}
Our predictions are neither far away from nor close to the measure results.
