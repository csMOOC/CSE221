\chapter{File System}

\section{Size of file cache}
In this part, we try to determine the file cache size.

\paragraph{Methodology}
If the file the fit into cache totally, then it would be very fast to read. If the file is too big that can not be put into cache totally, then read would be slower then that fir into cache totally. 

So I prepared 40 files with different sizes ranging from 1GB to 4GB. We read each file 10 times and calculate  read cycles/MB.

\paragraph{Predictions}
Our computer main memory is 8GB. So the cache must be less than 8GB; Besides, the project web page says it is a notable fraction of main memory and can be several GBs. So we predict it is 2GBs.

\paragraph{Results}
We present our measure results. By the way, we only include result from 3GB to 4GB, because the cache size is in this range.

\begin{center}
\begin{tabular}{l*{6}{c}r}
File Size             &  Cycles/MB\\
\hline
3000MB & 610 \\
3100MB & 614 \\
3200MB & 598 \\
3300MB & 622 \\
3400MB & 1965 \\
3500MB & 5498 \\
3600MB & 5572 \\
3700MB & 5503 \\
3800MB & 5673 \\
3900MB & 5657 \\
4000MB & 5598 \\

\end{tabular}
\end{center}

\begin{figure}[htbp] %  figure placement: here, top, bottom, or page
   \centering
   \includegraphics[width=5in]{./pics/41.jpg} 
   \caption{read cycles}
   \label{fig:read cycles}
\end{figure}

\paragraph{Discussion}
The graph shows that the file cache size is between 3300MB and 3500MB. Before this experiment, I did not realize that OS will use so many spaces for file cache. This optimisation speed up file reading time.

\section{File read time}
In this part, we report for both sequential and random access as a function of file size.

\paragraph{Methodology}
First, in order not to measure cached data, we want to set O\_DIRECT flag when opening a file, which could minimize cache effects of the I/O from this file. But Mac OS does not support O\_DIRECT. So we looked through Apple document and find we can set F\_NOCACHE in fcntl().

Besides, we use read() for sequential access, because read() will modify file pointer that fit the situation; However for random access it is bad to use read(), because we have to use lseek() to move the file pointer to target position which will significantly cost time. So we use pread() instead of read() for random access. Pread() works just like read() but reads from the specified position in the file without modifying the file pointer.

We provide several files with different sizes and iterate 100 times, then calculate  the average per-block read time.

\paragraph{Predictions}
Because we are using SSD, the speed of sequential and random access may be very similar to each other. Considering that we did not use file cache, we will fetch each block of data from disk. So I predict the speed is 19000 cycles per blocks, plus 1000 cycles for software.

\paragraph{Results}
We present our measure results. The base file is 4KB, and we define log(4KB) = 2.

\begin{figure}[htbp] %  figure placement: here, top, bottom, or page
   \centering
   \includegraphics[width=5in]{./pics/42.jpg} 
   \caption{read cycles per block}
   \label{fig:read cycles per block}
\end{figure}

\begin{center}
\begin{tabular}{l*{6}{c}r}
File Size             &  hardware & software & overall & Measured \\
\hline
4KB & 19000 & 1000 & 20000 & 401481\\ 
8KB & 19000 & 1000 & 20000 & 475677\\ 
16KB & 19000 & 1000 & 20000 & 501356\\
32KB & 19000 & 1000 & 20000 & 670260\\
64KB & 19000 & 1000 & 20000 & 489722\\
128KB & 19000 & 1000 & 20000 & 397495\\
256KB & 19000 & 1000 & 20000 & 293712\\
512KB & 19000 & 1000 & 20000 & 300106\\
1024KB & 19000 & 1000 & 20000 & 281106\\
2048KB & 19000 & 1000 & 20000 & 287629\\

\end{tabular}
\end{center}

Above is the result of sequential access. We can see on average it takes about 300000-600000 cycles to read each file block, far exceeding than we predicted previously.

\begin{center}
\begin{tabular}{l*{6}{c}r}
File Size             &  hardware & software & overall & Measured \\
\hline
4KB & 19000 & 1000 & 20000 & 420067\\ 
8KB & 19000 & 1000 & 20000 & 393597\\ 
16KB & 19000 & 1000 & 20000 & 502322\\
32KB & 19000 & 1000 & 20000 & 405538\\
64KB & 19000 & 1000 & 20000 & 425528\\
128KB & 19000 & 1000 & 20000 & 426442\\
256KB & 19000 & 1000 & 20000 & 504624\\
512KB & 19000 & 1000 & 20000 & 492654\\
1024KB & 19000 & 1000 & 20000 & 430804\\
2048KB & 19000 & 1000 & 20000 & 426658\\

\end{tabular}
\end{center}

Above is the result of random access. We can see on average it takes about 400000-500000 cycles to read each file block, far exceeding than we predicted previously.

\paragraph{Discussion}
As we have predicted, random access is almost as fast as sequential access due to SSD. But we predict cycles wrongly. Without file cache, it would be very expensive to do file reading. Each block would cost almost 300000-600000 cycles on average.

Then I remove F\_NOCACHE flag to do file reading, finding that it only takes about 1000-2000 cycles per block, which is so cheap compared with no cache. It speeds up over 100 times. So, in most situations open file with cache is good for program performance.

\section{Remote file read time}
In this section, we conduct the previous experiment for a remote file system.

\paragraph{Methodology}
We use the same method described in previous section. The only difference is that we now read a remote file. Note, page size in that machine is 8KB.

\paragraph{Predictions}
The remote machine use SSD, and the network bandwidth is 1000Mb/s, these two machines are in same LAN. So the effect of network may not seem so obvious.

Based on the results of previous section, we add 20\% overhead in hardware and software. Don't forget that the pagesize now is 8KB. And we think sequential access time is close to random access time. 

\paragraph{Results}

We present our measure results. The base file is 4KB, and we define log(4KB) = 2.

\begin{figure}[htbp] %  figure placement: here, top, bottom, or page
   \centering
   \includegraphics[width=4in]{./pics/43.jpg} 
   \caption{remote read cycles per block}
   \label{fig:remote read cycles per block}
\end{figure}

\begin{center}
\begin{tabular}{l*{6}{c}r}
File Size             &  hardware & software & overall & Measured \\
\hline
8KB & 800000 & 10000 & 810000 & 1060023\\ 
16KB & 800000 & 10000 & 810000 & 1037613\\ 
32KB & 800000 & 10000 & 810000 & 1155908\\
64KB & 800000 & 10000 & 810000 & 1127454\\
128KB & 800000 & 10000 & 810000 & 1134455\\
256KB & 800000 & 10000 & 810000 & 1105819\\
512KB & 800000 & 10000 & 810000 & 1085479\\
1024KB & 800000 & 10000 & 810000 & 1089600\\
2048KB & 800000 & 10000 & 810000 & 1074542\\

\end{tabular}
\end{center}

Above is the result of sequential access.

\begin{center}
\begin{tabular}{l*{6}{c}r}
File Size             &  hardware & software & overall & Measured \\
\hline
8KB & 800000 & 10000 & 810000 & 1043427\\ 
16KB & 800000 & 10000 & 810000 & 1065662\\ 
32KB & 800000 & 10000 & 810000 & 1058558\\
64KB & 800000 & 10000 & 810000 & 1073499\\
128KB & 800000 & 10000 & 810000 & 1073262\\
256KB & 800000 & 10000 & 810000 & 1077349\\
512KB & 800000 & 10000 & 810000 & 1074041\\
1024KB & 800000 & 10000 & 810000 & 1074543\\
2048KB & 800000 & 10000 & 810000 & 1044684\\

\end{tabular}
\end{center}

Above is the result of random access.

\paragraph{Discussion}
Due to previous experience, this time our estimation is very close to the measured results. And it seems that the overhead is not so much compared with file cache. If one machine is in China, another one is in US, maybe network is very expensive compared to other factors.

SSDs also make random access as fast as sequential access.

\paragraph{Question} What is the "network penalty" of accessing files over the network?  As we have predicted, compared with file cache, the network overhead is about 20\%, around 200000 cycles.

\section{Contention}
In this section, we report the average time to read one file system block of data as a function of the number of processes simultaneously performing the same operation on different files on the same disk (and not in the file buffer cache).

\paragraph{Methodology}
As previous experiment, we continue using F\_NOCACHE flag to disable file cache. In this experiment, we create several processes. Each process read different file which is of the same size : 1MB. And we iterate 100 times to get average data. 

\paragraph{Predictions}
We are sure that the more process number, the more cycles it spend on reading file. We think each read will result in a context switch to another process. We present predictions with results in the following table. We use 1MB file, including 256 blocks. Based on previous experiment on sequential reading 1MB file, when there is only 1 process, the reading cycles are 281106. When increasing a process, we add about 15000 cycles for hardware and 1000 for software.

\paragraph{Results}
We present our measure results(unit : cycles). 

\begin{center}
\begin{tabular}{l*{6}{c}r}
nprocesses             &  hardware & software & overall & Measured\\
\hline
1 & 280000 & 1000 & 281000 & 229003 \\
2 & 295000 & 2000 & 297000 & 253880 \\
3 & 310000 & 3000 & 313000 & 209028 \\
4 & 325000 & 4000 & 329000 & 240578 \\
5 & 340000 & 5000 & 345000 & 432147 \\
6 & 355000 & 6000 & 371000 & 438801 \\
7 & 370000 &7000 & 377000 & 459831 \\
8 & 385000 & 8000 & 393000 & 415745 \\
9 & 400000 & 9000 & 409000 & 474147 \\
10 & 415000 & 10000 & 425000 & 491004\\
11 & 430000 & 11000 & 441000 & 515341 \\
12 & 445000 & 12000 & 457000 & 515871 \\
13 & 460000 & 13000 & 473000 & 536629\\
14 & 475000 & 14000 & 489000 & 568728\\
15 & 490000 & 15000 & 505000 & 590147\\

\end{tabular}
\end{center}

\begin{figure}[htbp] %  figure placement: here, top, bottom, or page
   \centering
   \includegraphics[width=4.5in]{./pics/44.jpg} 
   \caption{average cycles per process}
   \label{fig:average cycles per process}
\end{figure}

\paragraph{Discussion}
We can see that generally, with the increasing of process, the average cycle increase too. 

Our prediction is so close to the measured results. I am very surprised, I had thought that the measured results may exceed millions of cycles due to context switch between processes.

When I set the file cache flag, the cycles reduce to about 6000-8000 per block.

If we use HDD, each read will take many seek time. Now we use SSD, the cost is very small. That's the big difference between SSD and HDD.